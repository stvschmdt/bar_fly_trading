{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StockFormer Attention Analysis\n",
    "\n",
    "Interactive exploration of the cross-attention StockFormer's internal representations.\n",
    "This notebook extracts and visualizes:\n",
    "\n",
    "1. **Cross-attention heatmaps** — which market timesteps each stock timestep attends to\n",
    "2. **Gate activations** — when the model uses market context vs stock-specific signal\n",
    "3. **Self-attention patterns** — temporal dependencies within the stock sequence\n",
    "4. **Attention pooling** — which timesteps matter most for the final prediction\n",
    "5. **Head specialization** — do different heads learn different patterns?\n",
    "6. **Input saliency** — which features drive the prediction (gradient-based)\n",
    "\n",
    "## Setup\n",
    "Run from the project root: `jupyter notebook notebooks/attention_analysis.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.insert(0, '..')  # add project root to path\n\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams['figure.dpi'] = 120\n\nfrom stockformer.model import CrossAttentionStockTransformer, create_model, infer_arch_from_state_dict\nfrom stockformer.config import BASE_FEATURE_COLUMNS, MARKET_FEATURE_COLUMNS\nfrom stockformer.explainability import (\n    AttentionExtractor,\n    make_extractor,\n    compute_input_saliency,\n    plot_attention_heatmap,\n    plot_attention_all_heads,\n    plot_cross_attention,\n    plot_cross_attention_all_heads,\n    plot_self_attention,\n    plot_gate_activations,\n    plot_gate_timeseries,\n    plot_attention_pooling,\n    plot_layer_evolution,\n    plot_head_specialization,\n    plot_saliency_map,\n    plot_saliency_summary,\n    generate_report,\n)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Device: {device}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model\n",
    "\n",
    "Two options:\n",
    "- **Option A**: Load a trained checkpoint\n",
    "- **Option B**: Create a randomly initialized model (for testing the viz pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ---- Option A: Load from checkpoint ----\n# Uncomment and set your checkpoint path:\n#\n# CHECKPOINT = '../stockformer/output/models/binary_3d_best.pt'\n# ckpt = torch.load(CHECKPOINT, map_location=device, weights_only=False)\n# arch = infer_arch_from_state_dict(ckpt['model_state_dict'], CHECKPOINT)\n# cfg_from_ckpt = {\n#     'd_model': arch['d_model'], 'nhead': arch['nhead'],\n#     'num_layers': arch['num_layers'], 'dim_feedforward': arch['dim_feedforward'],\n#     'dropout': arch.get('dropout', 0.1), 'market_layers': arch.get('market_layers', 2),\n#     'market_feature_dim': arch.get('market_dim', len(MARKET_FEATURE_COLUMNS)),\n#     'layer_drop': 0.0,\n#     'loss_name': 'coral' if arch.get('use_coral') else None,\n# }\n# model = create_model(\n#     feature_dim=arch['feature_dim'],\n#     label_mode=arch['output_mode'],\n#     bucket_edges=list(range(arch.get('num_buckets', 5) - 1)) if arch['output_mode'] == 'buckets' else None,\n#     cfg=cfg_from_ckpt,\n#     model_type='cross_attention',\n# )\n# model.load_state_dict(ckpt['model_state_dict'])\n# model = model.to(device).eval()\n# print(f'Loaded: {CHECKPOINT}')\n# print(f'Architecture: {arch}')\n\n# ---- Option B: Random model for testing ----\nFEATURE_DIM = len(BASE_FEATURE_COLUMNS)  # 41\nMARKET_DIM = len(MARKET_FEATURE_COLUMNS)  # 11\nSEQ_LEN = 60  # lookback window\n\ncfg = {\n    'd_model': 128, 'nhead': 8, 'num_layers': 4, 'dim_feedforward': 512,\n    'dropout': 0.1, 'market_layers': 2, 'market_feature_dim': MARKET_DIM,\n    'layer_drop': 0.0,\n}\nmodel = create_model(\n    feature_dim=FEATURE_DIM,\n    label_mode='binary',\n    bucket_edges=None,\n    cfg=cfg,\n    model_type='cross_attention',\n)\nmodel = model.to(device).eval()\n\nn_params = sum(p.numel() for p in model.parameters())\nprint(f'Model: CrossAttentionStockTransformer ({n_params:,} params)')\nprint(f'Features: {FEATURE_DIM} stock, {MARKET_DIM} market, seq_len={SEQ_LEN}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Input\n",
    "\n",
    "Either use real data from a CSV or generate random tensors for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Option A: Real data ----\n",
    "# import pandas as pd\n",
    "# from stockformer.dataset import StockDataset\n",
    "#\n",
    "# df = pd.read_csv('../data/all_data_AAPL.csv')\n",
    "# dataset = StockDataset(df, feature_cols=BASE_FEATURE_COLUMNS,\n",
    "#                        market_feature_cols=MARKET_FEATURE_COLUMNS,\n",
    "#                        target_col='close_3d_fwd_return',\n",
    "#                        lookback=SEQ_LEN, label_mode='binary')\n",
    "# x_real, y_real, market_real = dataset[-1]  # last sample\n",
    "# x = x_real.unsqueeze(0).to(device)\n",
    "# market_x = market_real.unsqueeze(0).to(device)\n",
    "\n",
    "# ---- Option B: Random tensors for testing ----\n",
    "torch.manual_seed(42)\n",
    "x = torch.randn(1, SEQ_LEN, FEATURE_DIM).to(device)\n",
    "market_x = torch.randn(1, SEQ_LEN, MARKET_DIM).to(device)\n",
    "\n",
    "print(f'Stock input:  {x.shape}')\n",
    "print(f'Market input: {market_x.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Attention Data\n",
    "\n",
    "The `AttentionExtractor` registers forward hooks that capture:\n",
    "- Cross-attention weights from each `GatedCrossAttention` layer\n",
    "- Gate values (sigmoid output controlling market context injection)\n",
    "- Self-attention weights from each `TransformerEncoderLayer`\n",
    "- Attention pooling weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = AttentionExtractor(model)\n",
    "\n",
    "with torch.no_grad():\n",
    "    with extractor:\n",
    "        output = model(x, market_x)\n",
    "\n",
    "attn = extractor.get_data()\n",
    "\n",
    "print(f'Output shape: {output.shape}')\n",
    "print(f'Cross-attn layers captured: {len(attn[\"cross_attn_weights\"])}')\n",
    "print(f'Gate layers captured:       {len(attn[\"gate_values\"])}')\n",
    "print(f'Self-attn layers captured:  {len(attn[\"self_attn_weights\"])}')\n",
    "print(f'Pool weights shape:         {attn[\"pool_weights\"].shape}')\n",
    "print()\n",
    "print(f'Cross-attn weight shape (per layer): {attn[\"cross_attn_weights\"][0].shape}')\n",
    "print(f'  -> [batch, heads, stock_len, market_len]')\n",
    "print(f'Gate value shape (per layer):        {attn[\"gate_values\"][0].shape}')\n",
    "print(f'  -> [batch, seq_len, d_model]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-Attention Heatmaps\n",
    "\n",
    "These show which market timesteps each stock timestep attends to.\n",
    "\n",
    "**What to look for:**\n",
    "- Diagonal pattern = each stock timestep attends to same-day market data\n",
    "- Vertical stripes = all stock timesteps attend to specific market events\n",
    "- Diffuse = model hasn't learned meaningful cross-attention yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average attention across heads for each layer\n",
    "for layer in range(len(attn['cross_attn_weights'])):\n",
    "    fig = plot_cross_attention(attn, layer=layer)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All 8 heads for layer 0 — do they specialize?\n",
    "fig = plot_cross_attention_all_heads(attn, layer=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gate Activations\n",
    "\n",
    "The gate controls how much market context is injected:\n",
    "- **Gate near 0**: stock-specific signal dominates (calm market)\n",
    "- **Gate near 1**: market context dominates (crash/rally)\n",
    "\n",
    "The timeseries plot shows mean gate value over the lookback window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gate activation heatmap (top 32 most variable dimensions)\n",
    "fig = plot_gate_activations(attn, layer=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean gate over time — all layers overlaid\n",
    "fig = plot_gate_timeseries(attn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Self-Attention Patterns\n",
    "\n",
    "Stock self-attention: how the stock sequence attends to itself across time.\n",
    "\n",
    "**What to look for:**\n",
    "- Diagonal = local attention (each day attends to itself)\n",
    "- Lower-triangular = causal pattern (attends to past only)\n",
    "- Off-diagonal hot spots = the model links distant days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-attention for layer 0 (avg over heads)\n",
    "fig = plot_self_attention(attn, layer=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare layer 0 vs last layer\n",
    "n_layers = len(attn['self_attn_weights'])\n",
    "if n_layers > 1:\n",
    "    fig = plot_self_attention(attn, layer=n_layers - 1,\n",
    "                              title=f'Self-Attention — Layer {n_layers-1} (last), Avg heads')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Attention Pooling\n",
    "\n",
    "After all encoder layers, the model uses learned attention pooling to\n",
    "aggregate the sequence into a single vector for the output head.\n",
    "\n",
    "**What to look for:**\n",
    "- Peak at recent timesteps = recency bias (expected)\n",
    "- Peaks at earlier timesteps = long-range dependency detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_attention_pooling(attn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Layer Evolution\n",
    "\n",
    "How attention patterns change across layers.\n",
    "\n",
    "- **Entropy decreasing** across layers = model sharpens attention (learns to focus)\n",
    "- **Entropy flat/high** = model hasn't learned to differentiate (possible underfitting)\n",
    "- **Sparsity increasing** = deeper layers attend to fewer positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_layer_evolution(attn, attention_type='cross')\n",
    "plt.show()\n",
    "\n",
    "fig = plot_layer_evolution(attn, attention_type='self')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Head Specialization\n",
    "\n",
    "Do different attention heads learn different behaviors?\n",
    "\n",
    "- **Different entropies** = some heads are focused, others diffuse (good)\n",
    "- **Different peak positions** = heads attend to different temporal regions (good)\n",
    "- **All heads identical** = redundancy, capacity waste (bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_head_specialization(attn, layer=0, attention_type='cross')\n",
    "plt.show()\n",
    "\n",
    "fig = plot_head_specialization(attn, layer=0, attention_type='self')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Input Saliency (Gradient-Based)\n",
    "\n",
    "Uses backpropagation to compute which input features the model is most\n",
    "sensitive to. This is different from attention — saliency measures the\n",
    "**causal effect** of each input on the output, not just what the model\n",
    "\"looks at\".\n",
    "\n",
    "Method: Input x Gradient (Grad-CAM analog for tabular data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_sal, market_sal = compute_input_saliency(model, x, market_x)\n",
    "\n",
    "print(f'Stock saliency shape:  {stock_sal.shape}  (seq_len x feature_dim)')\n",
    "print(f'Market saliency shape: {market_sal.shape}  (seq_len x market_dim)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock feature saliency heatmap (top 20 features)\n",
    "fig = plot_saliency_map(stock_sal, feature_names=BASE_FEATURE_COLUMNS, top_k=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market feature saliency heatmap (all 11 features)\n",
    "fig = plot_saliency_map(market_sal, feature_names=MARKET_FEATURE_COLUMNS,\n",
    "                        title='Market Input Saliency', top_k=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side feature importance summary\n",
    "fig = plot_saliency_summary(\n",
    "    stock_sal, market_sal,\n",
    "    stock_feature_names=BASE_FEATURE_COLUMNS,\n",
    "    market_feature_names=MARKET_FEATURE_COLUMNS,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Full Report Generation\n",
    "\n",
    "Generate all visualizations at once and save to disk as PNGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate all plots and save to disk\nsaved = generate_report(\n    model, x, market_x,\n    output_dir='../stockformer/output/explainability',\n    input_names=['Stock', 'Market'],\n    feature_names=[BASE_FEATURE_COLUMNS, MARKET_FEATURE_COLUMNS],\n)\n\nprint(f'\\nGenerated {len(saved)} figures:')\nfor name, path in saved.items():\n    print(f'  {name}: {path}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Comparing Samples\n",
    "\n",
    "Compare attention patterns for different stocks or market conditions.\n",
    "This is useful for understanding if the model behaves differently during\n",
    "high-volatility vs calm periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compare gate activations for two different inputs\n",
    "# (Uncomment when using real data)\n",
    "#\n",
    "# # Sample 1: calm market period\n",
    "# x1, _, m1 = dataset[100]\n",
    "# extractor = AttentionExtractor(model)\n",
    "# with torch.no_grad():\n",
    "#     with extractor:\n",
    "#         _ = model(x1.unsqueeze(0).to(device), m1.unsqueeze(0).to(device))\n",
    "# attn_calm = extractor.get_data()\n",
    "#\n",
    "# # Sample 2: volatile market period\n",
    "# x2, _, m2 = dataset[500]\n",
    "# extractor.clear()\n",
    "# with torch.no_grad():\n",
    "#     with extractor:\n",
    "#         _ = model(x2.unsqueeze(0).to(device), m2.unsqueeze(0).to(device))\n",
    "# attn_volatile = extractor.get_data()\n",
    "#\n",
    "# # Compare mean gate values\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# for layer in range(len(attn_calm['gate_values'])):\n",
    "#     g1 = attn_calm['gate_values'][layer][0].mean(dim=-1).numpy()\n",
    "#     g2 = attn_volatile['gate_values'][layer][0].mean(dim=-1).numpy()\n",
    "#     ax1.plot(g1, label=f'L{layer}', alpha=0.8)\n",
    "#     ax2.plot(g2, label=f'L{layer}', alpha=0.8)\n",
    "# ax1.set_title('Calm Market — Gate Activations')\n",
    "# ax2.set_title('Volatile Market — Gate Activations')\n",
    "# for ax in (ax1, ax2):\n",
    "#     ax.set_ylim(0, 1); ax.legend(); ax.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "print('Uncomment the cell above when using real data to compare market regimes.')"
   ]
  },
  {
   "cell_type": "code",
   "source": "def analyze_output_distribution(model, x, market_x=None, n_samples=100):\n    \"\"\"Run multiple random samples and analyze the output distribution.\"\"\"\n    model.eval()\n    all_logits = []\n    \n    with torch.no_grad():\n        for i in range(n_samples):\n            # Use provided inputs or generate random\n            if i == 0:\n                xi, mi = x, market_x\n            else:\n                xi = torch.randn_like(x)\n                mi = torch.randn_like(market_x) if market_x is not None else None\n            \n            args = (xi,) if mi is None else (xi, mi)\n            out = model(*args)\n            all_logits.append(out.cpu())\n    \n    logits = torch.cat(all_logits, dim=0)  # [n_samples, ...]\n    \n    if logits.dim() == 1:\n        # Regression\n        print(f'Regression output: mean={logits.mean():.4f}, std={logits.std():.4f}')\n        fig, ax = plt.subplots(figsize=(10, 4))\n        ax.hist(logits.numpy(), bins=50, color='steelblue', alpha=0.8, edgecolor='navy')\n        ax.set_xlabel('Predicted value')\n        ax.set_ylabel('Count')\n        ax.set_title(f'Regression Output Distribution (n={n_samples})')\n        ax.axvline(0, color='red', linestyle='--', alpha=0.5, label='zero')\n        ax.legend()\n        plt.show()\n        return logits\n    \n    # Classification — compute probabilities\n    if hasattr(model, 'use_coral') and model.use_coral:\n        # CORAL: cumulative sigmoid probabilities\n        cum_probs = torch.sigmoid(logits)  # [n, K-1]\n        ones = torch.ones(cum_probs.size(0), 1)\n        zeros = torch.zeros(cum_probs.size(0), 1)\n        extended = torch.cat([ones, cum_probs, zeros], dim=1)\n        probs = extended[:, :-1] - extended[:, 1:]\n        probs = probs.clamp(min=0)\n        preds = (cum_probs > 0.5).sum(dim=-1)\n        print(f'CORAL output: {logits.shape[1]} thresholds -> {probs.shape[1]} classes')\n        \n        # Plot cumulative probabilities\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n        for i in range(min(10, cum_probs.shape[0])):\n            ax1.plot(cum_probs[i].numpy(), alpha=0.5)\n        ax1.set_xlabel('Threshold k')\n        ax1.set_ylabel('P(class > k)')\n        ax1.set_title('CORAL Cumulative Probabilities (first 10 samples)')\n        ax1.set_ylim(0, 1)\n        ax1.grid(True, alpha=0.3)\n    else:\n        # Standard softmax\n        probs = F.softmax(logits, dim=-1)\n        preds = logits.argmax(dim=-1)\n        \n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n        # Per-class probability distribution\n        for c in range(probs.shape[1]):\n            ax1.hist(probs[:, c].numpy(), bins=30, alpha=0.5, label=f'Class {c}')\n        ax1.set_xlabel('Probability')\n        ax1.set_ylabel('Count')\n        ax1.set_title('Per-Class Probability Distribution')\n        ax1.legend()\n    \n    # Prediction distribution\n    pred_counts = torch.bincount(preds.long(), minlength=probs.shape[1])\n    ax2.bar(range(len(pred_counts)), pred_counts.numpy(), color='steelblue', alpha=0.8)\n    ax2.set_xlabel('Predicted class')\n    ax2.set_ylabel('Count')\n    ax2.set_title(f'Prediction Distribution (n={n_samples})')\n    \n    fig.tight_layout()\n    plt.show()\n    \n    # Confidence analysis\n    max_probs = probs.max(dim=-1).values\n    fig, ax = plt.subplots(figsize=(10, 4))\n    ax.hist(max_probs.numpy(), bins=50, color='coral', alpha=0.8, edgecolor='darkred')\n    ax.set_xlabel('Max probability (confidence)')\n    ax.set_ylabel('Count')\n    ax.set_title(f'Confidence Distribution — mean={max_probs.mean():.3f}')\n    ax.axvline(1.0/probs.shape[1], color='gray', linestyle='--', label='Uniform', alpha=0.5)\n    ax.legend()\n    plt.show()\n    \n    # Entropy of predictions\n    entropy = -(probs * (probs + 1e-10).log()).sum(dim=-1)\n    max_entropy = np.log(probs.shape[1])\n    print(f'Confidence: mean={max_probs.mean():.3f}, median={max_probs.median():.3f}')\n    print(f'Entropy: mean={entropy.mean():.3f} (max possible={max_entropy:.3f})')\n    print(f'Prediction breakdown: {dict(enumerate(pred_counts.tolist()))}')\n    \n    return probs\n\nprobs = analyze_output_distribution(model, x, market_x)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 13. Output Probability Analysis\n\nExamine the model's output distribution — the post-softmax probabilities\n(classification) or raw predictions (regression) — to understand confidence\nand calibration.\n\n**What to look for:**\n- **Overconfident**: P(class) near 1.0 for most samples = model is overfit or collapsed\n- **Underconfident**: P(class) near uniform = model hasn't learned signal\n- **Calibration**: Does 80% confidence actually mean 80% accuracy?\n- **CORAL ordinal**: Cumulative sigmoid probabilities should be monotonically decreasing",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}